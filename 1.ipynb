{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting C:\\Users\\Mahesh\\OneDrive\\Desktop\\BDD100K\\labels\\bdd100k_labels_images_train.json: 100%|██████████| 69863/69863 [02:14<00:00, 518.03it/s]\n",
      "Converting C:\\Users\\Mahesh\\OneDrive\\Desktop\\BDD100K\\labels\\bdd100k_labels_images_val.json: 100%|██████████| 10000/10000 [00:13<00:00, 730.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths to your dataset\n",
    "train_json_path = r\"C:\\Users\\Mahesh\\OneDrive\\Desktop\\BDD100K\\labels\\bdd100k_labels_images_train.json\"\n",
    "val_json_path = r\"C:\\Users\\Mahesh\\OneDrive\\Desktop\\BDD100K\\labels\\bdd100k_labels_images_val.json\"\n",
    "\n",
    "train_images_path = r\"C:\\Users\\Mahesh\\OneDrive\\Desktop\\BDD100K\\100k\\train\\trainA\"\n",
    "val_images_path = r\"C:\\Users\\Mahesh\\OneDrive\\Desktop\\BDD100K\\100k\\val\"\n",
    "\n",
    "yolo_train_labels_path = r\"C:\\Users\\Mahesh\\OneDrive\\Desktop\\BDD100K\\yolo_labels\\train\"\n",
    "yolo_val_labels_path = r\"C:\\Users\\Mahesh\\OneDrive\\Desktop\\BDD100K\\yolo_labels\\val\"\n",
    "\n",
    "# BDD100K class names\n",
    "bdd100k_classes = ['car', 'bus', 'truck', 'pedestrian', 'traffic sign', 'rider', 'bicycle', 'motorcycle', 'train', 'traffic light']\n",
    "class_to_id = {cls: idx for idx, cls in enumerate(bdd100k_classes)}\n",
    "\n",
    "# Create YOLO label directories\n",
    "os.makedirs(yolo_train_labels_path, exist_ok=True)\n",
    "os.makedirs(yolo_val_labels_path, exist_ok=True)\n",
    "\n",
    "# Function to convert BDD100K JSON to YOLO format\n",
    "def convert_bdd100k_to_yolo(json_path, images_path, output_labels_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for item in tqdm(data, desc=f\"Converting {json_path}\"):\n",
    "        img_name = item[\"name\"]\n",
    "        img_w, img_h = 1280, 720  # BDD100K image size\n",
    "\n",
    "        label_file = os.path.join(output_labels_path, img_name.replace(\".jpg\", \".txt\"))\n",
    "\n",
    "        with open(label_file, 'w') as label_f:\n",
    "            for label in item[\"labels\"]:\n",
    "                category = label[\"category\"]\n",
    "                if category not in class_to_id:\n",
    "                    continue  # Skip unknown categories\n",
    "\n",
    "                cls_id = class_to_id[category]\n",
    "\n",
    "                # Bounding box (normalized)\n",
    "                x1, y1, x2, y2 = label[\"box2d\"].values()\n",
    "                x_center = (x1 + x2) / 2 / img_w\n",
    "                y_center = (y1 + y2) / 2 / img_h\n",
    "                width = (x2 - x1) / img_w\n",
    "                height = (y2 - y1) / img_h\n",
    "\n",
    "                label_f.write(f\"{cls_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "# Convert train and val datasets\n",
    "convert_bdd100k_to_yolo(train_json_path, train_images_path, yolo_train_labels_path)\n",
    "convert_bdd100k_to_yolo(val_json_path, val_images_path, yolo_val_labels_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing labels: 137\n",
      "Missing image names: {'765f15fb-ef824308', '6e0fa2a3-a8f2be95', '5e464562-65962983', '6032f7e2-a7062c48', '7809356e-8e74fe0a', '647e8e1c-0141c492', '5d178102-9d5e50e2', '69061757-1459064f', '6f0cc882-8b3e2238', '7aca5bc0-23859d6f', '6cf7a093-29129f20', '58208859-5316743a', '68ce94b4-855f26a3', '54ea83be-ce461fd7', '68aca905-2c504ffd', '659a7a5e-92995bc3', '641d1337-af06cf4e', '6051b591-f7ec53c8', '6188d9b2-08ac3765', '62bd3830-aa6cb431', '7764bde0-03b1070a', '66fab43d-46c5b8f2', '65551742-016ff56a', '7a53506f-9c59128b', '612affad-42702404', '573809a9-e5a1b3b8', '7a36201f-1b550e67', '5b4727ac-d3fd8666', '6a76c075-d995ef0a', '70cc96e1-1802a164', '5ee6af4d-b34992f0', '76b72431-735ebc8f', '6d3eab65-1a1f9a3b', '6b1f5022-48037f59', '5d1905d8-875b2482', '75417b66-b26413f4', '749161f9-5281a0e0', '7adaeab3-10ec73b5', '67c665d7-662c6e08', '66ed92d6-a7529a59', '6a90b276-de74a29c', '6fcbd17b-9cd6c3a2', '5f9e9266-78dac9cc', '5ea6db6f-fa6b86fb', '6a42c0ab-5a1df402', '5de4c788-84dbc745', '7944f396-18fb3eba', '5c99e5ec-7aed1c3f', '5c4991da-2bcce0d1', '77d72c41-7e2d85d5', '69687999-3bd919f4', '7cddaf5e-2bdf3965', '74c17dc8-5da29363', '5b97b4c1-455baf62', '6739851f-37c84296', '5cd4c6d7-2051e443', '77c27140-244a8a88', '7481cb59-0c09de18', '6f7184c4-e7ec2226', '60595c14-113d4b8c', '75f56250-ee873a57', '7360cc7a-138da2b5', '75e66365-45cebb67', '67aafe4e-ba113a20', '79bb5311-1819cfb5', '66644eeb-b3f4ee0e', '5cf522b8-a0144375', '5de74ad7-9f445ae3', '734ecaa0-995f18ad', '6e9e3de7-318e1e75', '6235309f-a5cc4d73', '7832d791-a1efbf0d', '6fe61342-4d182f3a', '772eca25-a718f498', '5b7255d9-350ca0b7', '608640e2-c900aca1', '6bc8a49b-b03d2226', '71be111b-3d2c42bf', '64a355f1-02850b31', '5ee9e8f1-c1cd62b8', '5691a2c2-59c9f7ed', '5811624d-0c858bd8', '56bcdb00-0a1074d2', '7da4529f-fda6359b', '73918596-79c9e945', '6521230a-c379ab8a', '5b54f9f0-848cd09b', '72024824-3cf37c08', '5797f14c-159e4924', '738820d1-958724b2', '66838ab6-1d4062e5', '67c665d7-5d43cd3d', '79df0f3c-f11ba259', '68c29514-3c867490', '76a40920-fc78b7cf', '78c24fcc-bfe7d2da', '6d95cfb2-60926d6d', '7085ac8a-afc1e733', '5cc5736c-1b3b8a9b', '75b44995-fef0153f', '6731a55a-3ecf9a1d', '7751b61d-71561cda', '63ab7273-cc691816', '5e412e85-d1452b76', '69519e0a-60b2fb72', '7c6fa554-0c165e4f', '5b1b0c34-216cd6a5', '66cbb16a-010edd6c', '69ebe4cd-d5567704', '60855380-49af8931', '5b6dfbed-ea08eb7b', '6fdb819f-ce21ee5f', '7b0114cd-55ad1f37', '5ead49a0-f0566b6a', '64c28530-3876deb2', '65e0a5b6-08d3611c', '7df1ba2b-66efeea0', '681943bb-77050ee3', '61239730-1811efc0', '796e51dd-c9ed72e3', '66753960-186df654', '7a85221a-9b83dce8', '57dd03e1-7b415b61', '5fdc609c-d87d775f', '5ee6af4d-e02b3213', '621a49b2-0b00f7bd', '61676670-5ddf4aa4', '7afd081d-1b76748c', '73e07d14-c2d2f031', '5ccd45ac-62dae534', '5dc66059-52bfaff7', '679c58f7-e9a258c2', '7ddc420d-256fa72d', '718c99cd-80508f57', '79a6c89a-342f4751', '63ff2a76-e232da16', '7d2efdc4-6e8949dc'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define paths\n",
    "image_folder = \"C:/Users/Mahesh/OneDrive/Desktop/BDD100K/100k/train/trainA\"\n",
    "label_folder = \"C:/Users/Mahesh/OneDrive/Desktop/BDD100K/yolo_labels/train/\"\n",
    "\n",
    "# Get image and label filenames (without extensions)\n",
    "image_files = {f.split(\".\")[0] for f in os.listdir(image_folder) if f.endswith((\".jpg\", \".png\"))}\n",
    "label_files = {f.split(\".\")[0] for f in os.listdir(label_folder) if f.endswith(\".txt\")}\n",
    "\n",
    "# Find images without labels\n",
    "missing_labels = image_files - label_files\n",
    "print(f\"Total missing labels: {len(missing_labels)}\")\n",
    "print(\"Missing image names:\", missing_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "12.6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.version.cuda)  # Should match installed CUDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted all images without labels.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define paths\n",
    "image_folder = \"C:/Users/Mahesh/OneDrive/Desktop/BDD100K/100k/train/trainA\"\n",
    "label_folder = \"C:/Users/Mahesh/OneDrive/Desktop/BDD100K/yolo_labels/train/\"\n",
    "\n",
    "# Get image and label filenames (without extensions)\n",
    "image_files = {f for f in os.listdir(image_folder) if f.endswith((\".jpg\", \".png\"))}\n",
    "label_files = {f.split(\".\")[0] for f in os.listdir(label_folder) if f.endswith(\".txt\")}\n",
    "\n",
    "# Find images without labels\n",
    "for img in image_files:\n",
    "    img_name = os.path.splitext(img)[0]  # Remove extension\n",
    "    if img_name not in label_files:\n",
    "        os.remove(os.path.join(image_folder, img))  # Delete image\n",
    "\n",
    "print(\"Deleted all images without labels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All images have corresponding labels!\n",
      "✅ All labels have corresponding images!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def check_yolo_label_matching(image_dir, label_dir, image_exts=('jpg', 'png', 'jpeg')):\n",
    "    \"\"\"\n",
    "    Checks if all images in the dataset have corresponding YOLO labels and vice versa.\n",
    "    \n",
    "    :param image_dir: Path to the image directory\n",
    "    :param label_dir: Path to the YOLO label directory\n",
    "    :param image_exts: Tuple of valid image file extensions\n",
    "    \"\"\"\n",
    "    # Get all image and label filenames without extensions\n",
    "    image_files = {os.path.splitext(f)[0] for f in os.listdir(image_dir) if f.lower().endswith(image_exts)}\n",
    "    label_files = {os.path.splitext(f)[0] for f in os.listdir(label_dir) if f.endswith('.txt')}\n",
    "    \n",
    "    # Find mismatches\n",
    "    images_without_labels = image_files - label_files\n",
    "    labels_without_images = label_files - image_files\n",
    "    \n",
    "    # Print results\n",
    "    if images_without_labels:\n",
    "        print(f\"⚠️ {len(images_without_labels)} images without labels:\")\n",
    "        print(sorted(images_without_labels)[:10])  # Print first 10 mismatches\n",
    "    else:\n",
    "        print(\"✅ All images have corresponding labels!\")\n",
    "    \n",
    "    if labels_without_images:\n",
    "        print(f\"⚠️ {len(labels_without_images)} labels without images:\")\n",
    "        print(sorted(labels_without_images)[:10])  # Print first 10 mismatches\n",
    "    else:\n",
    "        print(\"✅ All labels have corresponding images!\")\n",
    "    \n",
    "    return images_without_labels, labels_without_images\n",
    "\n",
    "# Example usage\n",
    "image_dir = r\"C:/Users/Mahesh/OneDrive/Desktop/BDD100K/100k/train/trainA\"\n",
    "label_dir = r\"C:\\Users\\Mahesh\\OneDrive\\Desktop\\BDD100K\\yolo_labels\\train\"\n",
    "\n",
    "images_without_labels, labels_without_images = check_yolo_label_matching(image_dir, label_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original dataset paths\n",
    "train_img_path = r\"C:/Users/Mahesh/OneDrive/Desktop/BDD100K/100k/train/trainA\"\n",
    "train_label_path = r\"C:\\Users\\Mahesh\\OneDrive\\Desktop\\BDD100K\\yolo_labels\\train\"\n",
    "\n",
    "val_img_path = r\"C:/Users/Mahesh/OneDrive/Desktop/BDD100K/100k/val\"\n",
    "val_label_path = r\"C:\\Users\\Mahesh\\OneDrive\\Desktop\\BDD100K\\yolo_labels\\val\"\n",
    "\n",
    "test_img_path = \"C:/Users/Mahesh/OneDrive/Desktop/BDD100K/100k/test\"\n",
    "# test_label_path = \"C:/Users/Mahesh/OneDrive/Desktop/BDD100K/labels/test\"\n",
    "\n",
    "# Subset paths\n",
    "subset_train_img = \"C:/Users/Mahesh/OneDrive/Desktop/BDD100K/100k/train_subset\"\n",
    "subset_train_label = \"C:/Users/Mahesh/OneDrive/Desktop/BDD100K/yolo_labels/train_subset\"\n",
    "\n",
    "subset_val_img = \"C:/Users/Mahesh/OneDrive/Desktop/BDD100K/100k/val_subset\"\n",
    "subset_val_label = \"C:/Users/Mahesh/OneDrive/Desktop/BDD100K/yolo_labels/val_subset\"\n",
    "\n",
    "subset_test_img = \"C:/Users/Mahesh/OneDrive/Desktop/BDD100K/100k/test_subset\"\n",
    "subset_test_label = \"C:/Users/Mahesh/OneDrive/Desktop/BDD100K/labels/test_subset\"\n",
    "\n",
    "# # Generate subsets\n",
    "# train_subset_img, train_subset_label = create_subset(train_img_path, train_label_path, subset_train_img, subset_train_label)\n",
    "# val_subset_img, val_subset_label = create_subset(val_img_path, val_label_path, subset_val_img, subset_val_label)\n",
    "# test_subset_img, test_subset_label = create_subset(test_img_path, test_label_path, subset_test_img, subset_test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n",
      "✅ Using 10% subset dataset at: C:/Users/Mahesh/OneDrive/Desktop/BDD100K\\data_subset.yaml\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:01<00:00, 5.82MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78  Python-3.11.5 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce MX450, 2048MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:/Users/Mahesh/OneDrive/Desktop/BDD100K\\data_subset.yaml, epochs=2, time=None, patience=100, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=2, project=BDD100K_YOLOv8, name=yolov8n_train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=BDD100K_YOLOv8\\yolov8n_train\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.head.Detect           [10, [64, 128, 256]]          \n",
      "Model summary: 129 layers, 3,012,798 parameters, 3,012,782 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:01<00:00, 5.40MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Mahesh\\OneDrive\\Desktop\\BDD100K\\subset\\train\\labels... 34931 images, 9 backgrounds, 0 corrupt: 100%|██████████| 34931/34931 [05:48<00:00, 100.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\Mahesh\\OneDrive\\Desktop\\BDD100K\\subset\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Mahesh\\OneDrive\\Desktop\\BDD100K\\subset\\val\\labels... 5000 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5000/5000 [00:58<00:00, 86.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\Mahesh\\OneDrive\\Desktop\\BDD100K\\subset\\val\\labels.cache\n",
      "Plotting labels to BDD100K_YOLOv8\\yolov8n_train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mBDD100K_YOLOv8\\yolov8n_train\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/2     0.541G      1.539      1.355      1.074         41        640: 100%|██████████| 17466/17466 [1:48:46<00:00,  2.68it/s]  \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1250/1250 [04:11<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       5000      85165       0.42      0.285       0.28      0.158\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import Required Libraries\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Step 2: Check GPU Availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using Device: {device}\")\n",
    "\n",
    "# Step 3: Define Dataset Paths\n",
    "dataset_root = r\"C:/Users/Mahesh/OneDrive/Desktop/BDD100K\"\n",
    "full_yaml_path = r\"C:/Users/Mahesh/OneDrive/Desktop/BDD100K/data.yaml\"\n",
    "\n",
    "# Define image and label paths for train and val\n",
    "train_img_path = os.path.join(dataset_root, \"100k/train/trainA\")\n",
    "train_label_path = os.path.join(dataset_root, \"yolo_labels/train\")\n",
    "val_img_path = os.path.join(dataset_root, \"100k/val\")\n",
    "val_label_path = os.path.join(dataset_root, \"yolo_labels/val\")\n",
    "\n",
    "# Step 4: Choose Between Full Dataset and 10% Subset\n",
    "use_subset = True  # Set to False to use the full dataset\n",
    "\n",
    "if use_subset:\n",
    "    subset_yaml_path = os.path.join(dataset_root, \"data_subset.yaml\")  # Subset YAML file\n",
    "    subset_root = os.path.join(dataset_root, \"subset\")  # Directory for subset data\n",
    "\n",
    "    # Define subset paths\n",
    "    subset_train_img = os.path.join(subset_root, \"train/images\")\n",
    "    subset_train_label = os.path.join(subset_root, \"train/labels\")\n",
    "    subset_val_img = os.path.join(subset_root, \"val/images\")\n",
    "    subset_val_label = os.path.join(subset_root, \"val/labels\")\n",
    "\n",
    "    def create_subset(original_img_path, original_label_path, subset_img_path, subset_label_path, percentage=0.5):\n",
    "        \"\"\"\n",
    "        Create a subset of images and labels for YOLO training.\n",
    "        \n",
    "        - original_img_path: Path to original images\n",
    "        - original_label_path: Path to original YOLO label files\n",
    "        - subset_img_path: Destination for subset images\n",
    "        - subset_label_path: Destination for subset labels\n",
    "        - percentage: Fraction of data to use\n",
    "        \"\"\"\n",
    "        if not os.path.exists(subset_img_path):\n",
    "            os.makedirs(subset_img_path)\n",
    "        if not os.path.exists(subset_label_path):\n",
    "            os.makedirs(subset_label_path)\n",
    "\n",
    "        all_images = os.listdir(original_img_path)\n",
    "        sampled_images = random.sample(all_images, int(len(all_images) * percentage))\n",
    "\n",
    "        for image_file in sampled_images:\n",
    "            image_src = os.path.join(original_img_path, image_file)\n",
    "            image_dst = os.path.join(subset_img_path, image_file)\n",
    "\n",
    "            # Copy image\n",
    "            if not os.path.exists(image_dst):\n",
    "                os.link(image_src, image_dst)  # Hard link for efficiency\n",
    "\n",
    "            # Find corresponding label file (.txt)\n",
    "            label_file = os.path.splitext(image_file)[0] + \".txt\"\n",
    "            label_src = os.path.join(original_label_path, label_file)\n",
    "            label_dst = os.path.join(subset_label_path, label_file)\n",
    "\n",
    "            # Copy label if it exists\n",
    "            if os.path.exists(label_src):\n",
    "                if not os.path.exists(label_dst):\n",
    "                    os.link(label_src, label_dst)  # Hard link for labels too\n",
    "\n",
    "        return subset_img_path, subset_label_path\n",
    "\n",
    "    # Create train and validation subsets\n",
    "    train_subset_img, train_subset_label = create_subset(train_img_path, train_label_path, subset_train_img, subset_train_label)\n",
    "    val_subset_img, val_subset_label = create_subset(val_img_path, val_label_path, subset_val_img, subset_val_label)\n",
    "\n",
    "    # Create a new data.yaml for the subset\n",
    "    with open(subset_yaml_path, \"w\") as f:\n",
    "        f.write(f\"train: {train_subset_img}\\n\")\n",
    "        f.write(f\"val: {val_subset_img}\\n\")\n",
    "        f.write(\"nc: 10\\n\")\n",
    "        f.write(\"names: ['car', 'pedestrian', 'truck', 'bicycle', 'motorcycle', 'bus', 'rider', 'traffic light', 'traffic sign', 'train']\\n\")\n",
    "\n",
    "    yaml_path = subset_yaml_path  # Use subset for training\n",
    "    print(f\"✅ Using 10% subset dataset at: {subset_yaml_path}\")\n",
    "else:\n",
    "    yaml_path = full_yaml_path  # Use full dataset\n",
    "    print(f\"✅ Using full dataset at: {full_yaml_path}\")\n",
    "\n",
    "# Step 5: Load YOLOv8 Model (Nano Version for Faster Training)\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Step 6: Train Model\n",
    "results = model.train(\n",
    "    data=yaml_path,   # Use subset or full dataset\n",
    "    epochs=2,        # Increase if needed\n",
    "    imgsz=640,        # Lower resolution for MX450\n",
    "    batch=2,          # Reduce batch size for GPU memory\n",
    "    device=device,\n",
    "    workers=2,        # Reduce CPU usage\n",
    "    project=\"BDD100K_YOLOv8\",\n",
    "    name=\"yolov8n_train\"\n",
    ")\n",
    "\n",
    "# Step 7: Validate Model (Using Validation Set Instead of Test)\n",
    "val_results = model.val()\n",
    "print(\"\\n🔹 Validation Accuracy Metrics:\")\n",
    "print(f\"   - mAP@50: {val_results.box.map:.4f}\")\n",
    "print(f\"   - mAP@50-95: {val_results.box.maps.mean():.4f}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the trained model\n",
    "model = YOLO(\"runs/train/exp/weights/best.pt\")  # Update the path if needed\n",
    "\n",
    "# Define input video and output path\n",
    "input_video = \"input.mp4\"  # Change this to the path of your video\n",
    "output_video = \"output.mp4\"\n",
    "\n",
    "# Run object detection on the video\n",
    "results = model.predict(source=input_video, save=True, save_txt=True, conf=0.25)\n",
    "\n",
    "print(\"Detection completed. Check the output folder for results.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
